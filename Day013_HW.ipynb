{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.ptt.cc/bbs/NBA/index.html\"\n",
    "res=requests.get(url)\n",
    "soup=bs(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items=soup.find(\"div\",id=\"main-container\").find(\"div\",class_=\"r-list-container action-bar-margin bbs-screen\").find_all(\"div\",class_=\"r-ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作者 : ChenWay (Chenway)\n",
      "標題 : [討論] 這病毒是開菁英中心嗎\n",
      "時間 : Sun Mar 15 18:57:16 2020\n"
     ]
    }
   ],
   "source": [
    "base=\"https://www.ptt.cc\"\n",
    "y=0\n",
    "M=0\n",
    "d=0\n",
    "h=0\n",
    "m=0\n",
    "s=0\n",
    "new=None\n",
    "Month={\"Jan\":1,\"Feb\":2,\"Mar\":3,\"Apr\":4,\"May\":5,\"Jun\":6,\"Jul\":7,\"Aug\":8,\"Sep\":9,\"Oct\":10,\"Nov\":11,\"Dec\":12}\n",
    "for item in items:\n",
    "    if(item.find(\"a\")):\n",
    "        #print(item.find(\"a\").get(\"href\"))\n",
    "        res=requests.get(base+item.find(\"a\").get(\"href\"))\n",
    "        soup=bs(res.text)\n",
    "        info=soup.find(\"div\",id=\"main-container\").find(\"div\",id=\"main-content\").find_all(\"div\",class_=\"article-metaline\")\n",
    "        if(len(info)):\n",
    "            for i in info:\n",
    "                #print(i.find_all(\"span\")[0].text,end=\" : \")\n",
    "                #print(i.find_all(\"span\")[1].text)\n",
    "                if(i.find_all(\"span\")[0].text==\"時間\"):\n",
    "                    time=i.find_all(\"span\")[1].text.split()\n",
    "                    #print(i.find_all(\"span\")[1].text.split())\n",
    "                    if(int(time[4])>y):\n",
    "                        new=info\n",
    "                        y=int(time[4])\n",
    "                    elif(int(time[4])==y):\n",
    "                        if(Month[time[1]]>M):\n",
    "                            new=info\n",
    "                            M=Month[time[1]]\n",
    "                        elif(Month[time[1]]==M):\n",
    "                            if(int(time[2])>d):\n",
    "                                new=info\n",
    "                                d=int(time[2])\n",
    "                            elif(int(time[2])==d):\n",
    "                                if(int(time[3].split(\":\")[0])>h):\n",
    "                                    new=info\n",
    "                                    h=int(time[3].split(\":\")[0])\n",
    "                                elif(int(time[3].split(\":\")[0])==h):\n",
    "                                    if(int(time[3].split(\":\")[1])>m):\n",
    "                                        new=info\n",
    "                                        m=int(time[3].split(\":\")[1])\n",
    "                                    elif(int(time[3].split(\":\")[1])==m):\n",
    "                                        if(int(time[3].split(\":\")[2])>s):\n",
    "                                            new=info\n",
    "                                            s=int(time[3].split(\":\")[2])\n",
    "for i in new:\n",
    "    print(i.find_all(\"span\")[0].text,end=\" : \")\n",
    "    print(i.find_all(\"span\")[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=requests.get(url)\n",
    "soup=bs(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作者 : Price (Price)\n",
      "標題 : [轉錄]Lyotard 對於太陽板討論串的結論\n",
      "時間 : Sun May 16 01:54:33 2004\n",
      "-----------------------------\n",
      "作者 : Price (Price)\n",
      "標題 : [公告] 請停止一切關於本次活動的發言\n",
      "時間 : Mon May 24 00:43:00 2004\n",
      "-----------------------------\n",
      "作者 : Frankaze (神采風華)\n",
      "標題 : [轉錄]跟之前那篇比起來 我覺得這篇也應該轉過來\n",
      "時間 : Tue Jun  8 01:16:45 2004\n",
      "-----------------------------\n",
      "作者 : Frankaze (神采風華)\n",
      "標題 : [轉錄]再轉一篇好文來\n",
      "時間 : Tue Jun  8 09:02:23 2004\n",
      "-----------------------------\n",
      "作者 : Price (Price)\n",
      "標題 : [轉錄][情報] 夏洛特山貓系列\n",
      "時間 : Thu Jun 10 00:39:35 2004\n",
      "-----------------------------\n",
      "作者 : Price (Price)\n",
      "標題 : [轉錄]Re: [心得] 真是受不了糗爺....\n",
      "時間 : Thu Jun 10 00:51:35 2004\n",
      "-----------------------------\n",
      "作者 : Price (Price)\n",
      "標題 : [轉錄]總冠軍賽NO.2觀後感\n",
      "時間 : Thu Jun 10 12:05:07 2004\n",
      "-----------------------------\n",
      "作者 : AmuroNamie (原來太嗨真的會失眠^___^)\n",
      "標題 : [心得] Rasheed Wallace\n",
      "時間 : Fri Jun 11 15:06:09 2004\n",
      "-----------------------------\n",
      "作者 : toptree (  )\n",
      "標題 : 掌控球賽的男人\n",
      "時間 : Sat Jun 12 07:13:04 2004\n",
      "-----------------------------\n",
      "作者 : skchang (3EB板開板囉！)\n",
      "標題 : [閒聊] 說說2004季後賽名場面回顧\n",
      "時間 : Sat Jun 12 13:21:49 2004\n",
      "-----------------------------\n",
      "作者 : shineup ()\n",
      "標題 : [心得] 其實說穿了 就是活塞的防守太可怕了\n",
      "時間 : Sat Jun 12 13:12:47 2004\n",
      "-----------------------------\n",
      "作者 : cOvi (喵~)\n",
      "標題 : Re: [閒聊] 說說2004季後賽名場面回顧\n",
      "時間 : Sat Jun 12 16:43:07 2004\n",
      "-----------------------------\n",
      "作者 : ykshih (￼N￼Ns)\n",
      "標題 : Re: [閒聊] 說說2004季後賽名場面回顧\n",
      "時間 : Sat Jun 12 17:26:37 2004\n",
      "-----------------------------\n",
      "作者 : Frankaze (神采風華)\n",
      "標題 : Re: [閒聊] 說說2004季後賽名場面回顧\n",
      "時間 : Sat Jun 12 18:34:46 2004\n",
      "-----------------------------\n",
      "作者 : Price (Price)\n",
      "標題 : [轉錄]Re: 總冠軍賽NO.3觀後感\n",
      "時間 : Mon Jun 14 02:18:52 2004\n",
      "-----------------------------\n",
      "作者 : Frankaze (神采風華)\n",
      "標題 : [轉錄]Re: 總冠軍賽NO.3觀後感\n",
      "時間 : Mon Jun 14 02:34:33 2004\n",
      "-----------------------------\n",
      "作者 : star1 (第一次魔術表演不算成功)\n",
      "標題 : Re: [轉錄]Re: 總冠軍賽NO.3觀後感\n",
      "時間 : Mon Jun 14 07:16:30 2004\n",
      "-----------------------------\n",
      "作者 : coldspring (笑笑)\n",
      "標題 : Re: [轉錄]Re: 總冠軍賽NO.3觀後感\n",
      "時間 : Mon Jun 14 09:24:57 2004\n",
      "-----------------------------\n",
      "作者 : airbear (地圖)\n",
      "標題 : Re: Kobe is frustrated...\n",
      "時間 : Mon Jun 14 12:56:14 2004\n",
      "-----------------------------\n",
      "作者 : pennykidd (andre)\n",
      "標題 : Re: [轉錄]Re: 總冠軍賽NO.3觀後感\n",
      "時間 : Mon Jun 14 22:07:01 2004\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "a=soup.find(\"div\",id=\"main-container\").find(\"div\",id=\"action-bar-container\").find(\"div\",class_=\"action-bar\").find(\"div\",class_=\"btn-group btn-group-paging\").find_all(\"a\")\n",
    "for i in a:\n",
    "    if(i.text==\"最舊\"):\n",
    "        res=requests.get(base+i.get(\"href\"))\n",
    "        soup=bs(res.text)\n",
    "        items=soup.find(\"div\",id=\"main-container\").find(\"div\",class_=\"r-list-container action-bar-margin bbs-screen\").find_all(\"div\",class_=\"r-ent\")\n",
    "        for item in items:\n",
    "            if(item.find(\"a\")):\n",
    "                #print(item.find(\"a\").get(\"href\"))\n",
    "                res=requests.get(base+item.find(\"a\").get(\"href\"))\n",
    "                soup=bs(res.text)\n",
    "                info=soup.find(\"div\",id=\"main-container\").find(\"div\",id=\"main-content\").find_all(\"div\",class_=\"article-metaline\")\n",
    "                if(len(info)):\n",
    "                    for i in info:\n",
    "                        print(i.find_all(\"span\")[0].text,end=\" : \")\n",
    "                        print(i.find_all(\"span\")[1].text)\n",
    "            print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "res=requests.get(\"https://www.ptt.cc/bbs/index.html\")\n",
    "soup=bs(res.text)\n",
    "b_ent=soup.find_all(\"div\",class_=\"b-ent\")\n",
    "board=dict()\n",
    "for i in b_ent:\n",
    "    if(i.find(\"div\",class_=\"board-name\").text not in board):\n",
    "        board.update({i.find(\"div\",class_=\"board-name\").text:i.find(\"a\").get(\"href\")})\n",
    "#print(board)  \n",
    "cookies={\"over18\":\"1\"}\n",
    "for i in board:\n",
    "    url=board[i]\n",
    "    while(url):\n",
    "        #print(url)\n",
    "        res=requests.get(base+url,cookies=cookies)\n",
    "        soup=bs(res.text)\n",
    "        items=soup.find(\"div\",id=\"main-container\").find(\"div\",class_=\"r-list-container action-bar-margin bbs-screen\").find_all(\"div\",class_=\"r-ent\")\n",
    "        if(!os.path.exsit(\"Data\\\\ptt\\\\\"+i)):\n",
    "            os.makedirs(\"Data\\\\ptt\\\\\"+i,exsit_ok=True)\n",
    "        with open(\"Data\\\\ptt\\\\\"+i+\"\\\\\"+i+\"_\"+url[20:-5]+\".txt\",\"a+\",encoding=\"utf-8\") as f:\n",
    "            for item in items:\n",
    "                if(item.find(\"a\")):\n",
    "                    #print(item.find(\"a\").get(\"href\"))\n",
    "                    resp=requests.get(base+item.find(\"a\").get(\"href\"),cookies=cookies)\n",
    "                    soupp=bs(resp.text)\n",
    "                    info=soupp.find(\"div\",id=\"main-container\").find(\"div\",id=\"main-content\").find_all(\"div\",class_=\"article-metaline\")\n",
    "                    if(len(info)):\n",
    "                        for j in info:\n",
    "                            f.write(j.find_all(\"span\")[0].text+\" : \")\n",
    "                            f.write(j.find_all(\"span\")[1].text+\"\\n\")\n",
    "                            #print(j.find_all(\"span\")[0].text,end=\" : \")\n",
    "                            #print(j.find_all(\"span\")[1].text)\n",
    "                    f.write(\"\\n\")\n",
    "                    #print(\"-----------------------------\")\n",
    "        url=soup.find(\"div\",id=\"main-container\").find(\"div\",id=\"action-bar-container\").find(\"div\",class_=\"action-bar\").find(\"div\",class_=\"btn-group btn-group-paging\").find_all(\"a\")[1].get(\"href\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
